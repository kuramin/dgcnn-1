{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "import socket\n",
    "import importlib\n",
    "import os\n",
    "import imageio\n",
    "#import scipy.misc\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.getcwd()\n",
    "sys.path.append(BASE_DIR)\n",
    "sys.path.append(os.path.join(BASE_DIR, 'models'))\n",
    "sys.path.append(os.path.join(BASE_DIR, 'utils'))\n",
    "import provider\n",
    "from utils import pc_util\n",
    "from tf_util import log_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "NUM_POINT = 1024\n",
    "MODEL_PATH = 'log/model.ckpt'\n",
    "GPU_INDEX = 0\n",
    "MODEL = importlib.import_module('dgcnn')  # import network module\n",
    "DUMP_DIR = 'dump'\n",
    "VISU = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DUMP_DIR): os.mkdir(DUMP_DIR)\n",
    "LOG_FOUT = open(os.path.join(DUMP_DIR, 'log_evaluate.txt'), 'w')\n",
    "LOG_FOUT.write(\"BATCH_SIZE = 4, NUM_POINT = 1024, GPU_INDEX = 0\\n\")\n",
    "\n",
    "NUM_CLASSES = 40\n",
    "SHAPE_NAMES = [line.rstrip() for line in \\\n",
    "    open(os.path.join(BASE_DIR, 'data/modelnet40_ply_hdf5_2048/shape_names.txt'))] \n",
    "\n",
    "HOSTNAME = socket.gethostname()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelNet40 test files\n",
    "TEST_FILES = provider.get_data_files(\\\n",
    "    os.path.join(BASE_DIR, 'data/modelnet40_ply_hdf5_2048/test_files.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(num_votes):\n",
    "    with tf.device('/gpu:'+str(GPU_INDEX)):\n",
    "        pointclouds_pl, labels_pl = MODEL.placeholder_inputs(BATCH_SIZE, NUM_POINT)\n",
    "        is_training_pl = tf.placeholder(tf.bool, shape=())\n",
    "\n",
    "        # simple model\n",
    "        pred, end_points = MODEL.get_model(pointclouds_pl, is_training_pl)\n",
    "        loss = MODEL.get_loss(pred, labels_pl, end_points)\n",
    "        \n",
    "        # Add ops to save and restore all the variables.\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "    # Create a session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config.allow_soft_placement = True\n",
    "    config.log_device_placement = True\n",
    "    sess = tf.Session(config=config)\n",
    "\n",
    "    # Restore variables from disk.\n",
    "    saver.restore(sess, MODEL_PATH)\n",
    "    log_string(LOG_FOUT, \"Model restored.\")\n",
    "\n",
    "    ops = {'pointclouds_pl': pointclouds_pl,\n",
    "           'labels_pl': labels_pl,\n",
    "           'is_training_pl': is_training_pl,\n",
    "           'pred': pred,\n",
    "           'loss': loss}\n",
    "\n",
    "    eval_one_epoch(sess, ops, num_votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_one_epoch(sess, ops, num_votes=1, topk=1):\n",
    "    error_cnt = 0\n",
    "    is_training = False\n",
    "    total_correct = 0\n",
    "    total_seen = 0\n",
    "    loss_sum = 0\n",
    "    total_seen_class = [0 for _ in range(NUM_CLASSES)]\n",
    "    total_correct_class = [0 for _ in range(NUM_CLASSES)]\n",
    "    fout = open(os.path.join(DUMP_DIR, 'pred_label.txt'), 'w')\n",
    "    for fn in range(len(TEST_FILES)):\n",
    "        log_string(LOG_FOUT, '----'+str(fn)+'----')\n",
    "        current_data, current_label = provider.load_h5(TEST_FILES[fn])\n",
    "        current_data = current_data[:,0:NUM_POINT,:]\n",
    "        current_label = np.squeeze(current_label)\n",
    "        \n",
    "        file_size = current_data.shape[0]\n",
    "        num_batches = file_size // BATCH_SIZE\n",
    "        \n",
    "        for batch_idx in range(num_batches):\n",
    "            start_idx = batch_idx * BATCH_SIZE\n",
    "            end_idx = (batch_idx+1) * BATCH_SIZE\n",
    "            cur_batch_size = end_idx - start_idx\n",
    "            \n",
    "            # Aggregating START\n",
    "            batch_loss_sum = 0  # sum of losses for the batch\n",
    "            batch_pred_sum = np.zeros((cur_batch_size, NUM_CLASSES))  # predictions of classes for a batch of different clouds are summed up along different rotation angle\n",
    "            # batch_pred_classes = np.zeros((cur_batch_size, NUM_CLASSES))  # batch of one-hot predictions of classes\n",
    "            for vote_idx in range(num_votes):\n",
    "                rotated_data = provider.rotate_point_cloud_by_angle(current_data[start_idx:end_idx, :, :],\n",
    "                                                  vote_idx/float(num_votes) * np.pi * 2)\n",
    "                feed_dict = {ops['pointclouds_pl']: rotated_data,\n",
    "                             ops['labels_pl']: current_label[start_idx:end_idx],\n",
    "                             ops['is_training_pl']: is_training}\n",
    "                loss_val, pred_val = sess.run([ops['loss'], ops['pred']],\n",
    "                                          feed_dict=feed_dict)\n",
    "                batch_pred_sum += pred_val  # add predictions for current batch based on current angle to a sum\n",
    "                batch_loss_sum += (loss_val * cur_batch_size / float(num_votes))  # add loss value for current batch based on current angle to a sum\n",
    "            pred_val = np.argmax(batch_pred_sum, 1)  # class with maximal number of votes along different angles\n",
    "            # Aggregating END\n",
    "            \n",
    "            correct = np.sum(pred_val == current_label[start_idx:end_idx])\n",
    "            total_correct += correct\n",
    "            total_seen += cur_batch_size\n",
    "            loss_sum += batch_loss_sum\n",
    "\n",
    "            for i in range(start_idx, end_idx):  # for every cloud of current batch\n",
    "                l = current_label[i]\n",
    "                total_seen_class[l] += 1  # count total seen and total correct\n",
    "                total_correct_class[l] += (pred_val[i-start_idx] == l)\n",
    "                fout.write('%d, %d\\n' % (pred_val[i-start_idx], l))\n",
    "\n",
    "                # if prediction is wrong, save the three-view image as jpg\n",
    "                if pred_val[i-start_idx] != l and VISU: # ERROR CASE, DUMP!\n",
    "                    img_filename = '%d_label_%s_pred_%s.jpg' % (error_cnt, SHAPE_NAMES[l],\n",
    "                                                           SHAPE_NAMES[pred_val[i-start_idx]])\n",
    "                    img_filename = os.path.join(DUMP_DIR, img_filename)\n",
    "                    output_img = pc_util.point_cloud_three_views(np.squeeze(current_data[i, :, :]))\n",
    "                    #scipy.misc.imsave(img_filename, output_img)\n",
    "                    imageio.imwrite(img_filename, output_img)\n",
    "                    error_cnt += 1\n",
    "                \n",
    "    log_string(LOG_FOUT, 'eval mean loss: %f' % (loss_sum / float(total_seen)))\n",
    "    log_string(LOG_FOUT, 'eval accuracy: %f' % (total_correct / float(total_seen)))\n",
    "    log_string(LOG_FOUT, 'eval avg class acc: %f' % (np.mean(np.array(total_correct_class)/np.array(total_seen_class,dtype=np.float))))\n",
    "\n",
    "    # log accuracy of every class prediction\n",
    "    class_accuracies = np.array(total_correct_class)/np.array(total_seen_class,dtype=np.float)\n",
    "    for i, name in enumerate(SHAPE_NAMES):\n",
    "        log_string(LOG_FOUT, '%10s:\\t%0.3f' % (name, class_accuracies[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from log/model.ckpt\n",
      "Model restored.\n",
      "----0----\n",
      "----1----\n",
      "eval mean loss: 1.453585\n",
      "eval accuracy: 0.907212\n",
      "eval avg class acc: 0.879930\n",
      "  airplane:\t1.000\n",
      "   bathtub:\t0.960\n",
      "       bed:\t0.990\n",
      "     bench:\t0.700\n",
      " bookshelf:\t0.950\n",
      "    bottle:\t0.980\n",
      "      bowl:\t1.000\n",
      "       car:\t0.990\n",
      "     chair:\t0.960\n",
      "      cone:\t0.950\n",
      "       cup:\t0.750\n",
      "   curtain:\t0.900\n",
      "      desk:\t0.802\n",
      "      door:\t0.900\n",
      "   dresser:\t0.744\n",
      "flower_pot:\t0.300\n",
      " glass_box:\t0.930\n",
      "    guitar:\t1.000\n",
      "  keyboard:\t1.000\n",
      "      lamp:\t0.900\n",
      "    laptop:\t1.000\n",
      "    mantel:\t0.950\n",
      "   monitor:\t0.990\n",
      "night_stand:\t0.791\n",
      "    person:\t0.950\n",
      "     piano:\t0.950\n",
      "     plant:\t0.780\n",
      "     radio:\t0.950\n",
      "range_hood:\t0.960\n",
      "      sink:\t0.800\n",
      "      sofa:\t0.980\n",
      "    stairs:\t0.900\n",
      "     stool:\t0.800\n",
      "     table:\t0.820\n",
      "      tent:\t0.950\n",
      "    toilet:\t0.990\n",
      "  tv_stand:\t0.850\n",
      "      vase:\t0.830\n",
      "  wardrobe:\t0.650\n",
      "      xbox:\t0.600\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    with tf.Graph().as_default():\n",
    "        evaluate(num_votes=12)\n",
    "    LOG_FOUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
